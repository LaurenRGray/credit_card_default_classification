{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from patsy import dmatrices, dmatrix\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from xgboost import XGBClassifier\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model, svm\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "%matplotlib inline\n",
    "\n",
    "# make prettier plots\n",
    "%config InlineBackend.figure_format = 'svg' \n",
    "\n",
    "seed = 5\n",
    "np.random.seed(seed)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('cleaned_cc_default_data', 'rb')\n",
    "model_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering: Cluster Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into train/test & scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Analysis\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "cluster_cols = ['bill_amt_1', 'bill_amt_2', 'bill_amt_3', 'bill_amt_4', 'bill_amt_5', 'bill_amt_6', \n",
    " 'pay_0', 'pay_2', 'pay_3', 'pay_4', 'pay_5', 'pay_6', \n",
    "'pay_amt_1', 'pay_amt_2', 'pay_amt_3', 'pay_amt_4', 'pay_amt_5', 'pay_amt_6']\n",
    "\n",
    "# Add interactions\n",
    "cluster_str = cluster_cols[0]\n",
    "for i in cluster_cols[1:]:\n",
    "    cluster_str = cluster_str + ' + ' + i\n",
    "\n",
    "cluster_patsy = dmatrix(cluster_str, model_data)\n",
    "\n",
    "cluster_model = KMeans(n_clusters=5)\n",
    "cluster_model.fit(cluster_patsy)\n",
    "my_clusters = ['group_' + str(i) for i in cluster_model.labels_]\n",
    "\n",
    "model_data['my_clusters'] = my_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Patsy to create my X Matrix\n",
    "\n",
    "x_cols = ['my_clusters',\n",
    "        'age', 'sex', 'marital_status', 'education_level',  \n",
    "        'bill_amt_1', 'bill_amt_2', 'bill_amt_3', 'bill_amt_4', 'bill_amt_5', 'bill_amt_6', \n",
    "        'pay_0', 'pay_2', 'pay_3', 'pay_4', 'pay_5', 'pay_6', \n",
    "        'pay_amt_1', 'pay_amt_2', 'pay_amt_3', 'pay_amt_4', 'pay_amt_5', 'pay_amt_6', \n",
    "         'limit_balance']\n",
    "\n",
    "# Add interactions\n",
    "x_str = x_cols[0]\n",
    "for i in x_cols[1:]:\n",
    "    x_str = x_str + ' + ' + i\n",
    "x_str = x_str + '' # if I want to create new variables, add in empty string\n",
    "\n",
    "x_patsy = dmatrix(x_str, model_data)\n",
    "x_patsy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_clusters[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified train test split\n",
    "\n",
    "x_raw_clusters = x_patsy\n",
    "y_raw_clusters = np.array(model_data['default_payment_next_month'])\n",
    "\n",
    "sss1 = StratifiedShuffleSplit(n_splits=2, test_size=0.2, random_state=0)\n",
    "# sss2 = StratifiedShuffleSplit(n_splits=2, test_size=0.25, random_state=0)\n",
    "\n",
    "sss1.get_n_splits()\n",
    "for train_index, test_index in sss1.split(x_raw, y_raw):\n",
    "    x_train_clusters, x_test_clusters = x_raw_clusters[train_index,:], x_raw_clusters[test_index,:]\n",
    "    y_train_clusters, y_test_clusters = y_raw_clusters[train_index], y_raw_clusters[test_index]\n",
    "\n",
    "# use this later if I want to get fancy...\n",
    "# sss2.get_n_splits()\n",
    "# for train_index, test_index in sss2.split(x_mid, y_mid):\n",
    "#     x_train, x_val = x_mid[train_index,:], x_mid[test_index,:]\n",
    "#     y_train, y_val = y_mid[train_index], y_mid[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize my variables\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_norm_train = scaler.transform(x_train)\n",
    "# x_norm_val = scaler.transform(x_val)\n",
    "x_norm_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling with clusters\n",
    "\n",
    "- KNN\n",
    "- Logistic Regression\n",
    "- SVM\n",
    "- Linear SVC\n",
    "- Naive Bayes\n",
    "- Decision Tree Classifier\n",
    "- Random Forest\n",
    "- XGBoost ?\n",
    "- LightGBM ?\n",
    "- Neural Net ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for printing confusion matrices (see: https://gist.github.com/shaypal5/94c53d765083101efc0240d776a23823)\n",
    "\n",
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=18):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names, )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CV with 5 folds (knn)\n",
    "\n",
    "ks = range(1,301,50)\n",
    "param_grid = [{'n_neighbors': ks}]\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn_grid = GridSearchCV(knn, param_grid, cv=5, scoring='roc_auc', verbose=10, n_jobs=-1)\n",
    "knn_grid.fit(x_norm_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is my best model based on above\n",
    "# can run .predict(x_test)\n",
    "\n",
    "knn_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = print_confusion_matrix(confusion_matrix(y_train, knn_grid.predict(x_norm_train)), ['Class 0', 'Class 1'], figsize=(5, 4), fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run CV with 5 folds (logit)\n",
    "\n",
    "penalty = ['l1', 'l2']\n",
    "C = np.logspace(-3, 1, 100)\n",
    "param_grid = dict(C=C, penalty=penalty)\n",
    "\n",
    "logistic = linear_model.LogisticRegression(solver='liblinear', max_iter=10000)\n",
    "logistic_grid = GridSearchCV(logistic, param_grid, cv=5, scoring='roc_auc', verbose=10, n_jobs=-1)\n",
    "logistic_grid.fit(x_norm_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model for logistic regression (metric = C)\n",
    "\n",
    "logistic_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = print_confusion_matrix(confusion_matrix(y_train, logistic_grid.predict(x_norm_train)), ['Class 0', 'Class 1'], figsize=(5, 4), fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print coefficients\n",
    "\n",
    "logistic = linear_model.LogisticRegression() # ADD PARAMETERS FROM BEST ESTIMATE\n",
    "\n",
    "# then get coefficients\n",
    "# those coefficients will tell me which features are most important\n",
    "# purpose of this is interpretation of what really contributed to my model (presentation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because ROC-AUC scores between logit and RF are so close, can just opt to use logit since it will get rid of features (becuase it chose l1)\n",
    "# or if I decide to use RF, can then do EDA on features of low importance to inuit which features are important vs. not and why"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CV with 5 folds (SVM)\n",
    "\n",
    "C = np.logspace(-3, 1, 25)\n",
    "gammas = np.logspace(-3, 0, 25)\n",
    "param_grid = dict(C=C, gamma=gammas)\n",
    "\n",
    "svm1 = svm.SVC(kernel='rbf', probability=True)\n",
    "svm_grid = GridSearchCV(svm1, param_grid, cv=5, scoring='roc_auc', verbose=10, n_jobs=-1)\n",
    "svm_grid.fit(x_norm_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = print_confusion_matrix(confusion_matrix(y_train, svm_grid.predict(x_norm_train)), ['Class 0', 'Class 1'], figsize=(5, 4), fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC\n",
    "\n",
    "IS THE CODE CORRECT?\n",
    "\n",
    "HOW TO ADD TO ROC/AUC/SCORING?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run CV with 5 folds (Linear SVC)\n",
    "\n",
    "C = np.logspace(-3, 1, 25)\n",
    "# gammas = np.logspace(-3, 0, 25)\n",
    "param_grid = dict(C=C)\n",
    "# param_grid = dict(C=C, gamma=gammas)\n",
    "\n",
    "\n",
    "# LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
    "#      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
    "#      multi_class='ovr', penalty='l2', random_state=0, tol=1e-05, verbose=0)\n",
    "\n",
    "svc1 = LinearSVC()\n",
    "svc_grid = GridSearchCV(svc1, param_grid, cv=5, scoring='roc_auc', verbose=10, n_jobs=-1)\n",
    "svc_grid.fit(x_norm_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svc_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = print_confusion_matrix(confusion_matrix(y_train, svc_grid.predict(x_norm_train)), ['Class 0', 'Class 1'], figsize=(5, 4), fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Naive Bayes Model\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb_best = gnb.fit(x_norm_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = print_confusion_matrix(confusion_matrix(y_train, gnb_best.predict(x_norm_train)), ['Class 0', 'Class 1'], figsize=(5, 4), fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier GridSearchCV\n",
    "\n",
    "CORRECT CODE BELOW?\n",
    "\n",
    "ADD TO ROC-AUC & SCORING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run CV with 5 folds (Decision Tree Classifier)\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [50, 100, None],\n",
    "    'max_features': ['sqrt'], # what is this?\n",
    "    'min_samples_leaf': [1, 2, 5, 10],\n",
    "    'min_samples_split': [2, 3, 5, 10],\n",
    "    'n_estimators': [100, 200, 400, 1000]\n",
    "}\n",
    "\n",
    "dectree = DecisionTreeClassifier()\n",
    "dectree_grid = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='roc_auc', verbose=10, n_jobs=-1)\n",
    "dectree_grid.fit(x_norm_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dectree_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = print_confusion_matrix(confusion_matrix(y_train, dectree_grid.predict(x_norm_train)), ['Class 0', 'Class 1'], figsize=(5, 4), fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CV with 5 folds (Random Forest)\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [50, 100, None],\n",
    "    'max_features': ['sqrt'], # what is this?\n",
    "    'min_samples_leaf': [1, 2, 5, 10],\n",
    "    'min_samples_split': [2, 3, 5, 10],\n",
    "    'n_estimators': [100, 200, 400, 1000]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_grid = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='roc_auc', verbose=10, n_jobs=-1)\n",
    "rf_grid.fit(x_norm_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cm = print_confusion_matrix(confusion_matrix(y_train, rf_grid.predict(x_norm_train)), ['Class 0', 'Class 1'], figsize=(5, 4), fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Random Forest Feature Importances\n",
    "\n",
    "rf2 = RandomForestRegressor(n_estimators=200, max_depth = None)\n",
    "rf2.fit(x_norm_train, y_train)\n",
    "rf2.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip each feature importance weight with my columns\n",
    "\n",
    "pd.DataFrame(zip(list(rf2.feature_importances_), df.columns)) # sort by 0 later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run later and do feature importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best ROC_AUC for knn: %0.4f' % knn_grid.best_score_)\n",
    "print('Best ROC_AUC for logit: %0.4f' % logistic_grid.best_score_)\n",
    "print('Best ROC_AUC for svm: %0.4f' % svm_grid.best_score_)\n",
    "print('Best ROC_AUC for rf: %0.4f' % rf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score on F1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Params for knn: ', knn_grid.best_params_)\n",
    "print('Best Patams for logit: ', logistic_grid.best_params_)\n",
    "print('Best Params for svm: ', svm_grid.best_params_)\n",
    "print('Best Params for rf: ', rf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE QUESTIONS IN BELOW COMMENTED CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC for all the models\n",
    "\n",
    "# ARE THE X/Y VARIABLES THE CORRECT ONES TO USE HERE?\n",
    "# How does the ensembe work?\n",
    "\n",
    "# How to add new models above into this? E.g., Linear SVC, \n",
    "\n",
    "model_list = [knn_grid.best_estimator_, \n",
    "              logistic_grid.best_estimator_, \n",
    "              svm_grid.best_estimator_, \n",
    "              gnb_best, \n",
    "              rf_grid.best_estimator_,\n",
    "              'ensemble']\n",
    "model_name = ['knn', 'logit', 'svm', 'n_bayes', 'random_forest', 'ensemble']\n",
    "\n",
    "# Plot ROC curve for all my models\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "for i, model in enumerate(model_list):\n",
    "    if model == 'ensemble':\n",
    "        w1 = 0.10\n",
    "        w2 = 0.80\n",
    "        y_pred = (w1*logistic_grid.best_estimator_.predict_proba(x_norm_test)[:,1] \n",
    "                  + w2*rf_grid.best_estimator_.predict_proba(x_norm_test)[:,1]\n",
    "                  + (1-w1-w2)*gnb_best.predict_proba(x_norm_test)[:,1])\n",
    "    else:\n",
    "        y_pred = list(model.predict_proba(x_norm_test)[:,1])\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, y_pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label = (model_name[i] + ' AUC = %0.4f' % roc_auc))\n",
    "\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Examine the correlation of the model errors\n",
    "\n",
    "knn_error = y_train - knn_grid.predict_proba(x_norm_train)[:,1]\n",
    "logit_error = y_train - logistic_grid.predict_proba(x_norm_train)[:,1]\n",
    "svm_error = y_train - svm_grid.predict_proba(x_norm_train)[:,1]\n",
    "gnb_error = y_train - gnb_best.predict_proba(x_norm_train)[:,1]\n",
    "rf_error = y_train - rf_grid.predict_proba(x_norm_train)[:,1]\n",
    "\n",
    "error_df = pd.DataFrame()\n",
    "error_df['knn'] = knn_error\n",
    "error_df['logit'] = logit_error\n",
    "error_df['svm'] = svm_error\n",
    "error_df['gnb'] = gnb_error\n",
    "error_df['rand_forest'] = rf_error\n",
    "\n",
    "error_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [DELETE OR MOVE TO OTHER NOTEBOOK?]\n",
    "# Checking Random Forest Importances\n",
    "\n",
    "Importances views were created post-modeling to determine possible features to engineer or eliminate, checking if there were overlapping features that were hurting the models since most Random Forest models have high f2 scores and will potentially be chosen as final model for each social media."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!conda install rfpimp"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from rfpimp import *\n",
    "ranfor = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ranfor_twt.fit(X_train, y_train['web1a'])\n",
    "\n",
    "imp = importances(ranfor_twt, X_val, y_val['web1a'])\n",
    "viz = plot_importances(imp)\n",
    "viz.view()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ranfor2_inst.fit(X_train, y_train['web1b'])\n",
    "\n",
    "imp = importances(ranfor2_inst, X_val, y_val['web1b'])\n",
    "viz = plot_importances(imp)\n",
    "viz.view()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ranfor3_fb.fit(X_train, y_train['web1c'])\n",
    "\n",
    "imp = importances(ranfor3_fb, X_val, y_val['web1c'])\n",
    "viz = plot_importances(imp)\n",
    "viz.view()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ranfor5_yt.fit(X_train, y_train['web1e'])\n",
    "\n",
    "imp = importances(ranfor5_yt, X_val, y_val['web1e'])\n",
    "viz = plot_importances(imp)\n",
    "viz.view()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
